{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/pdfrag\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_PATH = \"../app/scenario/How-Women-Rise.pdf\"\n",
    "DEFAULT_CHUNK_SIZE = 3000\n",
    "DEFAULT_OVERLAP =10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\n"
     ]
    }
   ],
   "source": [
    "from doc_loader import Loader\n",
    "loader = Loader(pdf_path=PDF_PATH,chunk_size=DEFAULT_CHUNK_SIZE,chunk_overlap=DEFAULT_OVERLAP)\n",
    "docs = loader.load()\n",
    "print(len(docs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "with open('text.txt') as f:\n",
    "    text = f.read()\n",
    "\n",
    "texts = text_splitter.split_text(text)\n",
    "docs = [Document(page_content=t) for t in texts[:4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "¿Resumir las paginas? antes de meterlas en el vector store. ¿Se gana más?¿Se mejora alguna metrica?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "\n",
    "import textwrap\n",
    "chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "output_summary = chain.run(docs)\n",
    "wrapped_text = textwrap.fill(output_summary, width=100)\n",
    "print(wrapped_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting and summarizing in a single chain\n",
    "For convenience, we can wrap both the text splitting of our long document and summarizing in a single AnalyzeDocumentsChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import AnalyzeDocumentChain\n",
    "\n",
    "summarize_document_chain = AnalyzeDocumentChain(\n",
    "    combine_docs_chain=chain, text_splitter=text_splitter\n",
    ")\n",
    "summarize_document_chain.run(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Me quedo definiendo el modulo llm instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Index\n",
    "\n",
    "TODO: Probar https://weaviate.io/developers/weaviate/concepts/vector-index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retriever\n",
    "\n",
    "Añadir memoria para hacerlo conversacional. Mirar conversational retriever.\n",
    "\n",
    "https://python.langchain.com/docs/modules/memory/adding_memory#adding-memory-to-a-chat-model-based-llmchain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()\n",
    "retriever.search_kwargs['distance_metric'] = 'cos'\n",
    "retriever.search_kwargs['k'] = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine similarity is a measure of similarity between two non-zero vectors of an inner product space that measures the cosine of the angle between them. It's often used in information retrieval to measure the similarity between documents or pieces of tex\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UI\n",
    "Crear una app con gradio para cargar el pdf y hacer preguntas sobre\n",
    "el documento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdfrag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
